{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para el procesamiento de los datos extraídos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook donde se generan nuevos conjuntos de datos con ajustes necesarios para su posterior procesado, a partir de los datos extraidos en el notebook 01_data_extraction.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera general, comentar que se hace principalmente eliminación de columnas que no se van a utilizar así como renombrar otras. También se ajusta el tipo de dato para ciertas columnas para facilitar las operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados\n",
    "Unión del conjunto de datos de los resultados de carreras y de los sprints a partir de los CSVs generados. El nuevo conjunto de datos se exporta en formato CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultados carreras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer CSV original\n",
    "raw_race_results_df = pd.read_csv('../data/results_2000-2024.csv')\n",
    "\n",
    "# Convertir columna Results a un tipo de dato anidado en Python\n",
    "raw_race_results_df['Results'] = raw_race_results_df['Results'].apply(ast.literal_eval)\n",
    "rows = []\n",
    "results_expanded = []\n",
    "# Expandir columna Results para tener una fila por piloto a partir de los datos de Results\n",
    "for index, row in raw_race_results_df.iterrows():\n",
    "    results_list = row['Results']\n",
    "    for result in results_list:\n",
    "        rows.append(row.drop('Results'))\n",
    "        results_expanded.append(result)\n",
    "\n",
    "expanded_rows_df = pd.DataFrame(rows)\n",
    "results_normalized_df = pd.json_normalize(results_expanded) # Aplanar estructuras anidadas en el dataframe\n",
    "# Concatenar los resultados con el resto de datos\n",
    "race_results_df = pd.concat([expanded_rows_df.reset_index(drop=True), results_normalized_df.reset_index(drop=True)], axis=1)\n",
    "race_results_df['points'] = pd.to_numeric(race_results_df['points'], errors='coerce') # Convertir a integer\n",
    "\n",
    "# Convertir columna Circuit a un tipo de dato anidado en Python\n",
    "race_results_df['Circuit'] = race_results_df['Circuit'].apply(ast.literal_eval)\n",
    "circuits_normalized = pd.json_normalize(race_results_df['Circuit']) # Aplanar estructuras anidadas en el dataframe\n",
    "\n",
    "# Concatenar los circuitos con el resto de datos\n",
    "race_results_df = pd.concat([race_results_df.drop(columns=['Circuit']), circuits_normalized],axis=1)\n",
    "\n",
    "# Borrar columnas innecesarias\n",
    "race_results_df.drop(columns=['url', 'Location.lat', 'Location.long', 'Location.locality', 'Location.country', 'Driver.url', 'Driver.permanentNumber', 'Constructor.url', 'time'], axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "race_results_df.rename(columns={'Driver.driverId': 'driverId', 'Driver.code': 'driverCode', 'Driver.givenName': 'driverName', 'Driver.familyName': 'driverSurname', 'Driver.dateOfBirth': 'driverBirth',\n",
    "'Driver.nationality':'driverNationality', 'Constructor.constructorId': 'constructorId', 'Constructor.name': 'constructorName', 'Constructor.nationality': 'constructorNationality', 'Time.millis': 'timeMillis', 'Time.time': 'time', 'FastestLap.rank': 'fastestLapRank',\n",
    "'FastestLap.lap': 'fastestLap', 'FastestLap.Time.time': 'fastestLapTime', 'FastestLap.AverageSpeed.speed': 'fastestLapAverageSpeed', 'FastestLap.AverageSpeed.units': 'fastestLapAverageSpeedUnit'},  inplace=True)\n",
    "\n",
    "# Convertir tipos de datos\n",
    "race_results_df = race_results_df.astype({'position': 'int64', 'points': 'int64', 'grid': 'int64', 'laps': 'int64'})\n",
    "\n",
    "race_results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultados sprint races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer CSV original\n",
    "raw_sprint_results_df = pd.read_csv('../data/sprint_results_2000-2024.csv')\n",
    "\n",
    "# Convertir columna Results a un tipo de dato anidado en Python\n",
    "raw_sprint_results_df['SprintResults'] = raw_sprint_results_df['SprintResults'].apply(ast.literal_eval)\n",
    "\n",
    "# Expandir columna SprintResults para tener una fila por piloto a partir de los datos de SprintResults\n",
    "rows = []\n",
    "results_expanded = []\n",
    "for index, row in raw_sprint_results_df.iterrows():\n",
    "    results_list = row['SprintResults']\n",
    "    for result in results_list:\n",
    "        rows.append(row.drop('SprintResults'))\n",
    "        results_expanded.append(result)\n",
    "\n",
    "expanded_rows_df = pd.DataFrame(rows)\n",
    "results_normalized_df = pd.json_normalize(results_expanded) # Aplanar estructuras anidadas en el dataframe\n",
    "\n",
    "# Concatenar los resultados de las carreras sprint con el resto de datos\n",
    "sprint_results_df = pd.concat([expanded_rows_df.reset_index(drop=True), results_normalized_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "sprint_results_df['points'] = pd.to_numeric(sprint_results_df['points'], errors='coerce') # Convertir a integer\n",
    "\n",
    "# Convertir columna Circuit a un tipo de dato anidado en Python\n",
    "sprint_results_df['Circuit'] = sprint_results_df['Circuit'].apply(ast.literal_eval) \n",
    "circuits_normalized = pd.json_normalize(sprint_results_df['Circuit']) # Aplanar estructuras anidadas en el dataframe\n",
    "\n",
    "# Concatenar los circuitos con el resto de datos\n",
    "sprint_results_df = pd.concat([sprint_results_df.drop(columns=['Circuit']), circuits_normalized],axis=1)\n",
    "\n",
    "# Borrar columnas innecesarias\n",
    "sprint_results_df.drop(columns=['url', 'Location.lat',\t'Location.long', 'Location.locality', 'Location.country', 'Driver.url', 'Driver.permanentNumber', 'Constructor.url', 'time'], axis=1, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "sprint_results_df.rename(columns={'Driver.driverId': 'driverId', 'Driver.code': 'driverCode', 'Driver.givenName': 'driverName', 'Driver.familyName': 'driverSurname', 'Driver.dateOfBirth': 'driverBirth',\n",
    "'Driver.nationality':'driverNationality', 'Constructor.constructorId': 'constructorId', 'Constructor.name': 'constructorName', 'Constructor.nationality': 'constructorNationality', 'Time.millis': 'timeMillis', 'Time.time': 'time', 'FastestLap.rank': 'fastestLapRank',\n",
    "'FastestLap.lap': 'fastestLap', 'FastestLap.Time.time': 'fastestLapTime', 'FastestLap.AverageSpeed.speed': 'fastestLapAverageSpeed', 'FastestLap.AverageSpeed.units': 'fastestLapAverageSpeedUnit', 'position':'sprintPosition', 'points':'sprintPoints', 'grid':'sprintGrid', 'laps':'sprintLaps'},  inplace=True)\n",
    "\n",
    "# Convertir\n",
    "sprint_results_df = sprint_results_df.astype({'sprintPosition': 'int64', 'sprintPoints': 'int64', 'sprintGrid': 'int64', 'sprintLaps': 'int64'})\n",
    "\n",
    "sprint_results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unión de ambos conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir los resultados de las carreras sprint con los rows de los resultados de las carreras\n",
    "sprint_results_df['sprintRace']= True\n",
    "sprint_results_df.head()\n",
    "all_results_df = pd.merge(race_results_df, sprint_results_df[['circuitId', 'season', 'driverId','sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints','sprintRace']], on=['circuitId', 'season', 'driverId'], how='left')\n",
    "\n",
    "# Rellenar NaN en la columna sprintRace con False, indicando que no hubo sprint race para el Gran Premio si era NaN \n",
    "all_results_df['sprintRace'] = all_results_df['sprintRace'].fillna(False)\n",
    "\n",
    "# Convertir valores\n",
    "all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']] = all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Valores a columnas NaN\n",
    "all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']] = all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']].fillna(0)\n",
    "all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']] = all_results_df[['fastestLapRank', 'fastestLap', 'sprintPosition', 'sprintGrid', 'sprintLaps', 'sprintPoints']].astype(int)\n",
    "\n",
    "# Nueva columna con la suma de los puntos para un fin de semana: Race points + Sprint points\n",
    "all_results_df['weekendPoints'] = all_results_df['points'] + all_results_df['sprintPoints']\n",
    "\n",
    "# Crear nuevo CSV\n",
    "all_results_df.to_csv('../data/race_and_sprint_results_2000-2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de los puntos acumulados por piloto a lo largo de la temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df['cumulative_points'] = all_results_df.groupby(['season','driverId'])['weekendPoints'].cumsum()\n",
    "all_results_df.tail(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Circuitos por temporada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para obtener el continente al que pertenece cada país donde se celebra gran premio para añadirlo al conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent_name(country_name):\n",
    "    country_code = pc.country_name_to_country_alpha2(country_name)\n",
    "    continent_code = pc.country_alpha2_to_continent_code(country_code)\n",
    "    continent_dict = {\n",
    "        \"NA\": \"North America\",\n",
    "        \"SA\": \"South America\",\n",
    "        \"AS\": \"Asia\",\n",
    "        \"AF\": \"Africa\",\n",
    "        \"OC\": \"Oceania\",\n",
    "        \"EU\": \"Europe\",\n",
    "        \"AQ\" : \"Antarctica\"\n",
    "    }\n",
    "    return continent_dict[continent_code]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza del conjunto de datos de circuitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer CSV de circuitos\n",
    "df_seasons_circuits = pd.read_csv('../data/seasons_circuits_2000-2024.csv')\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df_dropped_circuits = df_seasons_circuits.drop(columns=['time', 'ThirdPractice', 'FirstPractice', 'SecondPractice', 'url', 'Sprint', 'Qualifying'])\n",
    "\n",
    "# Convertir a una estructura anidada en Python\n",
    "df_dropped_circuits['Circuit'] = df_dropped_circuits['Circuit'].apply(ast.literal_eval)\n",
    "\n",
    "# Aplanar circuitos y concatenarlo al dataframe original, eliminando la columna con la estructura anidada\n",
    "df_flat_circuits = pd.concat(\n",
    "    [df_dropped_circuits.drop(columns=['Circuit']), pd.json_normalize(df_dropped_circuits['Circuit'])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Renombrar columnas\n",
    "df_flat_circuits.rename(columns={'Location.lat':'latitude', 'Location.long':'longitude', 'Location.locality':'locality', 'Location.country':'country'}, inplace=True)\n",
    "\n",
    "# Borrar más columnas\n",
    "df_flat_circuits.drop(columns=['url'], inplace=True)\n",
    "\n",
    "# Reemplazar algunos nombres de países para hacerlo compatible con la librería pycountry_convert\n",
    "df_flat_circuits['country'] = df_flat_circuits['country'].replace({'UK': 'United Kingdom', 'USA': 'United States', 'UAE': 'United Arab Emirates', 'Korea': 'South Korea'})\n",
    "\n",
    "# Asignar contienente a cada fila\n",
    "df_flat_circuits['continent'] = df_flat_circuits['country'].apply(get_continent_name)\n",
    "\n",
    "# Crear nuevo CSV\n",
    "df_flat_circuits.to_csv('../data/cleaned_circuits_2000-2024.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitstops\n",
    "Limpieza del conjunto de datos de los pitstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CSV original\n",
    "raw_pitstops_df = pd.read_csv('../data/raw_pitstops.csv')\n",
    "\n",
    "# Convertir columna PitStops a una estructura anidada en Python\n",
    "raw_pitstops_df['PitStops'] = raw_pitstops_df['PitStops'].apply(ast.literal_eval)\n",
    "\n",
    "# Expandir columna PitStops para tener una fila por piloto a partir de los datos de PitStops\n",
    "rows = []\n",
    "pitstops_expanded = []\n",
    "for index, row in raw_pitstops_df.iterrows():\n",
    "    pitstop_list = row['PitStops']\n",
    "    for pitstop_item in pitstop_list:\n",
    "        rows.append(row.drop('PitStops'))\n",
    "        pitstops_expanded.append(pitstop_item)\n",
    "\n",
    "expanded_rows_df = pd.DataFrame(rows)\n",
    "pitstops_normalized_df = pd.json_normalize(pitstops_expanded) # Aplanar estructuras anidadas en el dataframe\n",
    "\n",
    "# Aplanar circuitos y concatenarlo al dataframe original, eliminando la columna con la estructura anidada\n",
    "pitstops_rows_df = pd.concat([expanded_rows_df.reset_index(drop=True), pitstops_normalized_df.reset_index(drop=True)], axis=1)\n",
    " \n",
    "pitstops_rows_df['Circuit'] = pitstops_rows_df['Circuit'].apply(ast.literal_eval) # Aplanar estructuras anidadas en el dataframe\n",
    "# Extraer el valor de la key circuitId en el diccionario Circuit y añadir circuitId a una columna nueva en el dataframe\n",
    "pitstops_rows_df['circuitId'] = pitstops_rows_df['Circuit'].apply(lambda x: x.get(\"circuitId\"))\n",
    "\n",
    "# Eliminar columnas\n",
    "pitstops_rows_df.drop(columns=['url', 'Circuit','time'], axis=1, inplace=True)\n",
    "\n",
    "# Añadir nombre de los pilotos al dataframe utilizando los valores presentes en el CSV race_and_sprint_results_2000-2024.csv\n",
    "results_df = pd.read_csv('../data/race_and_sprint_results_2000-2024.csv')\n",
    "teams_from_results_df = results_df[['season', 'driverId', 'driverName', 'driverSurname', 'constructorId', 'constructorName']]\n",
    "teams_from_results_df = teams_from_results_df.groupby(['season', 'driverId']).first().reset_index()\n",
    "drivers_pitstops_df = pd.merge(pitstops_rows_df, teams_from_results_df[['season','driverId','driverName', 'driverSurname', 'constructorId', 'constructorName']], on=['season','driverId'], how='left')\n",
    "drivers_pitstops_df['driverFullName'] = drivers_pitstops_df['driverName'] + ' ' + drivers_pitstops_df['driverSurname']\n",
    "\n",
    "# Crear nuevo CSV\n",
    "drivers_pitstops_df.to_csv('../data/cleaned_pitstops.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
